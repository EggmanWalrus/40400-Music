{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Culture and Psychological States\n",
    "## Replicating and Expanding DeWall et al. 2011 \"Tuning in to Psychological Change\"<sup>1</sup>\n",
    "\n",
    "DeWall et al. 2011 tested three music lyric legisign relationships for evidence that replication of self-focus and antisocial legisigns has increased over time in song lyrics from the Billboard Hot 100 and that the replication of other-focus, social interactions, and positive emotion legisigns has decreased. Confirming their expectations, they argue that this pattern in musical legisign replication can be generalized to say that U.S. culture has become more self-focused and antisocial. If we accept Frith's assertion that songs \"provide people with the means to articulate [...] feelings\" (1996: 164)<sup>2</sup>, then this finding of increasingly antisocial and self-focused language within the most popular U.S. songs should be suggestive of a more general cultural psychological state. In Peircean terms, this means that, on one level, each word in the lyrics would be a replica of a dicent indexical legisign. For instance, replications of \"self-focus\" I/me/my/mine words stand for singer singing the word (and for listener who uses the word to articulate their own feelings), indexing their internal psychological state, and producing a dicent interpretant associating that psychological state with themselves. Today, we're going to attempt to replicate and expand DeWall et al.'s study (using Billboard Hot 100 song lyrics from 1950-2015) by answering the following questions:\n",
    "\n",
    "1. Can we identify increasing self-focus (first person singular pronouns) and decreasing other-focus (\"communion,\" first person plural pronouns)?\n",
    "2. Can we identify decreasing \"social connection\" legisign replication?\n",
    "3. Is there an increase in antisocial legisign replication and a decrease in pro-social legisign replication?\n",
    "4. Extending DeWall et al.'s study, are the topics and themes in songs changing as well? Do topics of music also reflect this anti-social, self-focus interpretation?\n",
    "\n",
    "Our data comes from a couple (see [here](https://github.com/kevinschaich/billboard) and [here](https://towardsdatascience.com/billboard-hot-100-analytics-using-data-to-understand-the-shift-in-popular-music-in-the-last-60-ac3919d39b49)) of public Github repositories that compiled extensive historical data about the Billboard Hot 100 from 1950-2015, along with data about the music itself from Spotify.\n",
    "    \n",
    "Note: The authors of the study tested the frequency of Social Connection, Anti-social, Positive Emotion (unless the few words provided in the text on page 3 are the only words they checked) word categories using the LIWC (Language Inquiry Word Count) 2007 dictionary, which we will use as well. In the original study, DeWall et al. consider music genre as dummy variables in their regression models, as well as changes in ranking formula  to account for digital downloads and streamed media. We will not consider these factors for analysis as genre is a bit tricky to pin down because so many songs cross genre-boundaries, the genres themselves have changed through time, and this information is often not available in early songs from the 50s. We will instead consider the overall effects across genres and ranking formulas.\n",
    "    \n",
    "---------------------------------\n",
    "  \n",
    "<sup>1</sup>DeWall, C. N., Pond, R. S., Jr., Campbell, W. K., & Twenge, J. M. 2011. \"Tuning in to Psychological Change: Linguistic Markers of Psychological Traits and Emotions Over Time in Popular U.S. Song Lyrics.\" *Psychology of Aesthetics*, Creativity, and the Arts.\n",
    "\n",
    "<sup>2</sup>Frith, Simon. 1996. “Songs as Texts.” In *Performing Rites: On the Value of Popular Music*. Cambridge,\n",
    "MA: Harvard University Press, pp. 158-182.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jon Clindaniel\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import nltk\n",
    "import string\n",
    "from gensim import corpora, models\n",
    "import collections\n",
    "import re\n",
    "\n",
    "# Some Functions from Last Time to get us started:\n",
    "def get_wordnet_pos(word):\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": nltk.corpus.wordnet.ADJ,\n",
    "                \"N\": nltk.corpus.wordnet.NOUN,\n",
    "                \"V\": nltk.corpus.wordnet.VERB,\n",
    "                \"R\": nltk.corpus.wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, nltk.corpus.wordnet.NOUN)\n",
    "\n",
    "def get_lemmas(text):\n",
    "\n",
    "    stop = nltk.corpus.stopwords.words('english') + list(string.punctuation)\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower()) if i not in stop]\n",
    "    lemmas = [nltk.stem.WordNetLemmatizer().lemmatize(t, get_wordnet_pos(t)) for t in tokens]\n",
    "    return lemmas\n",
    "\n",
    "def get_tokens(text):\n",
    "    # drop punctuation, but keep stopwords for initial word counting\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = [i for i in nltk.word_tokenize(text.lower())]\n",
    "    return tokens\n",
    "\n",
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=2):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = models.ldamulticore.LdaMulticore(corpus=corpus, id2word=dictionary, num_topics=num_topics, workers=8)\n",
    "        model_list.append(model)\n",
    "        coherence_model = models.coherencemodel.CoherenceModel(model=model, corpus=corpus, dictionary=dictionary, coherence='u_mass')\n",
    "        coherence_values.append(coherence_model.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values\n",
    "\n",
    "def fill_topic_weights(df_row, bow_corpus):\n",
    "    # Fill topic weights for topics in songs\n",
    "    try:\n",
    "        for i in ldamodel[bow_corpus[df_row.name]]:\n",
    "            df_row[str(i[0])] = i[1]\n",
    "    except:\n",
    "        return df_row\n",
    "    return df_row\n",
    "\n",
    "def top_songs_by_topic(ldamodel, corpus, ntop=1):\n",
    "    topn_songs_by_topic = {}\n",
    "    for i in range(len(ldamodel.print_topics())):\n",
    "        # For each topic, collect the most representative song(s) (i.e. highest probability containing words belonging to topic):\n",
    "        top = sorted(zip(range(len(corpus)), ldamodel[corpus]), reverse=True, key=lambda x: abs(dict(x[1]).get(i, 0.0)))\n",
    "        topn_songs_by_topic[i] = [j[0] for j in top[:ntop]]\n",
    "        # Print out the topn songs for each topic and return their indices as a dictionary for further analysis:\n",
    "        print(\"Topic \" + str(i))\n",
    "        print(music_df[['title','year','artist']].loc[topn_songs_by_topic[i]])\n",
    "        print(\"*******************************\")\n",
    "    return topn_songs_by_topic\n",
    "\n",
    "'''\n",
    "The following code is adapted from psyLex.\n",
    "psyLex: an open-source implementation of the Linguistic Inquiry Word Count\n",
    "Created by Sean C. Rife, Ph.D.\n",
    "srife1@murraystate.edu // seanrife.com // @seanrife\n",
    "Licensed under the MIT License\n",
    "https://github.com/seanrife/psyLex\n",
    "'''\n",
    "\n",
    "# Function to read in an LIWC-style dictionary\n",
    "\n",
    "def readDict(dictionaryPath):\n",
    "    catList = collections.OrderedDict()\n",
    "    catLocation = []\n",
    "    wordList = {}\n",
    "    finalDict = collections.OrderedDict()\n",
    "\n",
    "    # Check to make sure the dictionary is properly formatted\n",
    "    with open(dictionaryPath, \"r\") as dictionaryFile:\n",
    "        for idx, item in enumerate(dictionaryFile):\n",
    "            if \"%\" in item:\n",
    "                catLocation.append(idx)\n",
    "        if len(catLocation) > 2:\n",
    "            # There are apparently more than two category sections; throw error and die\n",
    "            sys.exit(\"Invalid dictionary format. Check the number/locations of the category delimiters (%).\")\n",
    "\n",
    "    # Read dictionary as lines\n",
    "    with open(dictionaryPath, \"r\") as dictionaryFile:\n",
    "        lines = dictionaryFile.readlines()\n",
    "\n",
    "    # Within the category section of the dictionary file, grab the numbers associated with each category\n",
    "    for line in lines[catLocation[0] + 1:catLocation[1]]:\n",
    "        catList[re.split(r'\\t+', line)[0]] = [re.split(r'\\t+', line.rstrip())[1]]\n",
    "\n",
    "    # Now move on to the words\n",
    "    for idx, line in enumerate(lines[catLocation[1] + 1:]):\n",
    "        # Get each line (row), and split it by tabs (\\t)\n",
    "        workingRow = re.split('\\t', line.rstrip())\n",
    "        wordList[workingRow[0]] = list(workingRow[1:])\n",
    "\n",
    "    # Merge the category list and the word list\n",
    "    for key, values in wordList.items():\n",
    "        if not key in finalDict:\n",
    "            finalDict[key] = []\n",
    "        for catnum in values:\n",
    "            workingValue = catList[catnum][0]\n",
    "            finalDict[key].append(workingValue)\n",
    "    return (finalDict, catList.values())\n",
    "\n",
    "# Function to count and categorize words based on an LIWC dictionary\n",
    "\n",
    "def wordCount(data, dictOutput):\n",
    "    finalDict, catList = dictOutput\n",
    "    \n",
    "    # Create a new dictionary for the output\n",
    "    outList = collections.OrderedDict()\n",
    "\n",
    "    # Number of non-dictionary words\n",
    "    nonDict = 0\n",
    "\n",
    "    # Convert to lowercase\n",
    "    data = data.lower()\n",
    "\n",
    "    # Tokenize and create a frequency distribution\n",
    "    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(data)\n",
    "\n",
    "    fdist = nltk.FreqDist(tokens)\n",
    "    wc = len(tokens)\n",
    "\n",
    "    # Using the Porter stemmer for wildcards, create a stemmed version of the data\n",
    "    porter = nltk.PorterStemmer()\n",
    "    stems = [porter.stem(word) for word in tokens]\n",
    "    fdist_stem = nltk.FreqDist(stems)\n",
    "\n",
    "    # Access categories and populate the output dictionary with keys\n",
    "    for cat in catList:\n",
    "        outList[cat[0]] = 0\n",
    "\n",
    "    # Dictionaries are more useful\n",
    "    fdist_dict = dict(fdist)\n",
    "    fdist_stem_dict = dict(fdist_stem)\n",
    "\n",
    "    # Number of classified words\n",
    "    classified = 0\n",
    "\n",
    "    for key in finalDict:\n",
    "        if \"*\" in key and key[:-1] in fdist_stem_dict:\n",
    "            classified = classified + fdist_stem_dict[key[:-1]]\n",
    "            for cat in finalDict[key]:\n",
    "                outList[cat] = outList[cat] + fdist_stem_dict[key[:-1]]\n",
    "        elif key in fdist_dict:\n",
    "            classified = classified + fdist_dict[key]\n",
    "            for cat in finalDict[key]:\n",
    "                outList[cat] = outList[cat] + fdist_dict[key]\n",
    "\n",
    "    # Calculate the percentage of words classified\n",
    "    if wc > 0:\n",
    "        percClassified = (float(classified) / float(wc)) * 100\n",
    "    else:\n",
    "        percClassified = 0\n",
    "\n",
    "    # Return the categories, the words used, the word count, the number of words classified, and the percentage of words classified.\n",
    "    return [outList, tokens, wc, classified, percClassified]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_df = pd.read_csv('music_df.csv')\n",
    "music_df['year_bin'] = music_df['year_bin'].apply(lambda x: '20'+x if (x == '10s') or (x == '00s') else '19'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['lyrics', 'num_syllables', 'pos', 'year', 'fog_index', 'flesch_index',\n",
      "       'num_words', 'num_lines', 'title', 'f_k_grade', 'artist',\n",
      "       'difficult_words', 'num_dupes', 'neg', 'neu', 'compound', 'id',\n",
      "       'danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness',\n",
      "       'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo',\n",
      "       'duration_ms', 'time_signature', 'uri', 'analysis_url',\n",
      "       'artist_with_features', 'year_bin', 'image', 'cluster', 'Gender'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>num_syllables</th>\n",
       "      <th>pos</th>\n",
       "      <th>year</th>\n",
       "      <th>fog_index</th>\n",
       "      <th>flesch_index</th>\n",
       "      <th>num_words</th>\n",
       "      <th>num_lines</th>\n",
       "      <th>title</th>\n",
       "      <th>f_k_grade</th>\n",
       "      <th>...</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>uri</th>\n",
       "      <th>analysis_url</th>\n",
       "      <th>artist_with_features</th>\n",
       "      <th>year_bin</th>\n",
       "      <th>image</th>\n",
       "      <th>cluster</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mona Lisa, Mona Lisa, men have named you\\nYou'...</td>\n",
       "      <td>189.0</td>\n",
       "      <td>0.199</td>\n",
       "      <td>1950</td>\n",
       "      <td>5.2</td>\n",
       "      <td>88.74</td>\n",
       "      <td>145</td>\n",
       "      <td>17</td>\n",
       "      <td>Mona Lisa</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>86.198</td>\n",
       "      <td>207573.0</td>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:3k5ycyXX5qsCjLd7R2vphp</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/3k5y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950s</td>\n",
       "      <td>https://i.scdn.co/image/a4c0918f13b67aa8d9f4ea...</td>\n",
       "      <td>String Lover</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I wanna be Loved\\nBy Andrews Sisters\\n\\nOooo-o...</td>\n",
       "      <td>270.9</td>\n",
       "      <td>0.224</td>\n",
       "      <td>1950</td>\n",
       "      <td>4.4</td>\n",
       "      <td>82.31</td>\n",
       "      <td>189</td>\n",
       "      <td>31</td>\n",
       "      <td>I Wanna Be Loved</td>\n",
       "      <td>3.3</td>\n",
       "      <td>...</td>\n",
       "      <td>170.869</td>\n",
       "      <td>198027.0</td>\n",
       "      <td>5</td>\n",
       "      <td>spotify:track:4UY81WrDU3jTROGaKuz4uZ</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/4UY8...</td>\n",
       "      <td>Gordon Jenkins</td>\n",
       "      <td>1950s</td>\n",
       "      <td>https://i.scdn.co/image/42e4dc3ab9b190056a1ca1...</td>\n",
       "      <td>String Lover</td>\n",
       "      <td>Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I was dancing with my darling to the Tennessee...</td>\n",
       "      <td>174.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>1950</td>\n",
       "      <td>5.2</td>\n",
       "      <td>88.74</td>\n",
       "      <td>138</td>\n",
       "      <td>16</td>\n",
       "      <td>Tennessee Waltz</td>\n",
       "      <td>2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>86.335</td>\n",
       "      <td>182733.0</td>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:6DKt9vMnMN0HmlnK3EAHRQ</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/6DKt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950s</td>\n",
       "      <td>https://i.scdn.co/image/353b05113b1a140d64d83d...</td>\n",
       "      <td>String Lover</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Each time I hold someone new\\nMy arms grow col...</td>\n",
       "      <td>135.9</td>\n",
       "      <td>0.231</td>\n",
       "      <td>1950</td>\n",
       "      <td>4.4</td>\n",
       "      <td>99.23</td>\n",
       "      <td>117</td>\n",
       "      <td>18</td>\n",
       "      <td>I'll Never Be Free</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>82.184</td>\n",
       "      <td>158000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>spotify:track:0KnD456yC5JuweN932Ems3</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/0KnD...</td>\n",
       "      <td>Kay Starr</td>\n",
       "      <td>1950s</td>\n",
       "      <td>https://i.scdn.co/image/4bd427bb9181914d0fa448...</td>\n",
       "      <td>String Lover</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unfortunately, we are not licensed to display ...</td>\n",
       "      <td>46.8</td>\n",
       "      <td>0.079</td>\n",
       "      <td>1950</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.79</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>All My Love</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.314</td>\n",
       "      <td>190933.0</td>\n",
       "      <td>4</td>\n",
       "      <td>spotify:track:05sXHTLqIpwywbpui1JT4o</td>\n",
       "      <td>https://api.spotify.com/v1/audio-analysis/05sX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1950s</td>\n",
       "      <td>https://i.scdn.co/image/353b05113b1a140d64d83d...</td>\n",
       "      <td>String Lover</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics  num_syllables    pos  \\\n",
       "0  Mona Lisa, Mona Lisa, men have named you\\nYou'...          189.0  0.199   \n",
       "1  I wanna be Loved\\nBy Andrews Sisters\\n\\nOooo-o...          270.9  0.224   \n",
       "2  I was dancing with my darling to the Tennessee...          174.6  0.351   \n",
       "3  Each time I hold someone new\\nMy arms grow col...          135.9  0.231   \n",
       "4  Unfortunately, we are not licensed to display ...           46.8  0.079   \n",
       "\n",
       "   year  fog_index  flesch_index  num_words  num_lines               title  \\\n",
       "0  1950        5.2         88.74        145         17           Mona Lisa   \n",
       "1  1950        4.4         82.31        189         31    I Wanna Be Loved   \n",
       "2  1950        5.2         88.74        138         16     Tennessee Waltz   \n",
       "3  1950        4.4         99.23        117         18  I'll Never Be Free   \n",
       "4  1950        6.0         69.79         32          3         All My Love   \n",
       "\n",
       "   f_k_grade  ...    tempo  duration_ms  time_signature  \\\n",
       "0        2.9  ...   86.198     207573.0               3   \n",
       "1        3.3  ...  170.869     198027.0               5   \n",
       "2        2.9  ...   86.335     182733.0               3   \n",
       "3        0.9  ...   82.184     158000.0               3   \n",
       "4        6.0  ...  123.314     190933.0               4   \n",
       "\n",
       "                                    uri  \\\n",
       "0  spotify:track:3k5ycyXX5qsCjLd7R2vphp   \n",
       "1  spotify:track:4UY81WrDU3jTROGaKuz4uZ   \n",
       "2  spotify:track:6DKt9vMnMN0HmlnK3EAHRQ   \n",
       "3  spotify:track:0KnD456yC5JuweN932Ems3   \n",
       "4  spotify:track:05sXHTLqIpwywbpui1JT4o   \n",
       "\n",
       "                                        analysis_url  artist_with_features  \\\n",
       "0  https://api.spotify.com/v1/audio-analysis/3k5y...                   NaN   \n",
       "1  https://api.spotify.com/v1/audio-analysis/4UY8...        Gordon Jenkins   \n",
       "2  https://api.spotify.com/v1/audio-analysis/6DKt...                   NaN   \n",
       "3  https://api.spotify.com/v1/audio-analysis/0KnD...             Kay Starr   \n",
       "4  https://api.spotify.com/v1/audio-analysis/05sX...                   NaN   \n",
       "\n",
       "  year_bin                                              image       cluster  \\\n",
       "0    1950s  https://i.scdn.co/image/a4c0918f13b67aa8d9f4ea...  String Lover   \n",
       "1    1950s  https://i.scdn.co/image/42e4dc3ab9b190056a1ca1...  String Lover   \n",
       "2    1950s  https://i.scdn.co/image/353b05113b1a140d64d83d...  String Lover   \n",
       "3    1950s  https://i.scdn.co/image/4bd427bb9181914d0fa448...  String Lover   \n",
       "4    1950s  https://i.scdn.co/image/353b05113b1a140d64d83d...  String Lover   \n",
       "\n",
       "   Gender  \n",
       "0    male  \n",
       "1   Group  \n",
       "2  female  \n",
       "3    male  \n",
       "4  female  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(music_df.columns)\n",
    "music_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
